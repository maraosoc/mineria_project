# ğŸŒ³ MinerÃ­a de Datos - Pipeline de ClasificaciÃ³n Bosque/No-Bosque

Pipeline completo de procesamiento de imÃ¡genes Sentinel-2 y clasificaciÃ³n de cobertura forestal usando AWS EMR, S3 y Spark MLlib.

---

## ğŸ“‹ Tabla de Contenidos

- [Arquitectura](#arquitectura)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Pipeline de Datos](#pipeline-de-datos)
- [ConfiguraciÃ³n AWS](#configuraciÃ³n-aws)
- [EjecuciÃ³n](#ejecuciÃ³n)
- [Monitoreo](#monitoreo)
- [Desarrollo Local](#desarrollo-local)

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sentinel-2     â”‚
â”‚  Raw Data (S3)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            AWS EMR Cluster (Spark 3.x)                  â”‚
â”‚                                                          â”‚
â”‚  Step 1: Procesar Sentinel                              â”‚
â”‚  â”œâ”€ Leer SAFE files (rasterio)                         â”‚
â”‚  â”œâ”€ Calcular Ã­ndices (NDVI, NDWI)                      â”‚
â”‚  â””â”€ Guardar â†’ s3://bucket/01_processed/                â”‚
â”‚                                                          â”‚
â”‚  Step 2: Generar MÃ¡scaras                               â”‚
â”‚  â”œâ”€ SCL classification                                  â”‚
â”‚  â”œâ”€ Clear sky mask                                      â”‚
â”‚  â””â”€ Guardar â†’ s3://bucket/02_masks/                    â”‚
â”‚                                                          â”‚
â”‚  Step 3: TabulaciÃ³n con Polars                          â”‚
â”‚  â”œâ”€ Extraer valores por pÃ­xel                          â”‚
â”‚  â”œâ”€ Calcular estadÃ­sticas temporales                    â”‚
â”‚  â””â”€ Guardar â†’ s3://bucket/03_features/                 â”‚
â”‚                                                          â”‚
â”‚  Step 4: Rasterizar Labels                              â”‚
â”‚  â”œâ”€ Vectores bosque â†’ raster                           â”‚
â”‚  â”œâ”€ Aplicar erosiÃ³n de bordes                          â”‚
â”‚  â””â”€ Guardar â†’ s3://bucket/04_labels/                   â”‚
â”‚                                                          â”‚
â”‚  Step 5: Unir Features + Labels                         â”‚
â”‚  â”œâ”€ Join espacial                                       â”‚
â”‚  â””â”€ Guardar â†’ s3://bucket/05_training_data/            â”‚
â”‚                                                          â”‚
â”‚  Step 6: Entrenar Modelos (Spark MLlib)                 â”‚
â”‚  â”œâ”€ Random Forest                                       â”‚
â”‚  â”œâ”€ Gradient Boosted Trees                             â”‚
â”‚  â”œâ”€ OptimizaciÃ³n hiperparÃ¡metros                       â”‚
â”‚  â””â”€ Guardar â†’ s3://bucket/06_models/                   â”‚
â”‚                                                          â”‚
â”‚  Step 7: EvaluaciÃ³n                                      â”‚
â”‚  â””â”€ Guardar mÃ©tricas â†’ s3://bucket/07_evaluation/      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Predicciones   â”‚
â”‚  (S3 + Athena)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Estructura del Proyecto

```
mineria_project/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ aws_config.yaml          # ConfiguraciÃ³n AWS (regiÃ³n, bucket, etc)
â”‚   â”œâ”€â”€ emr_config.json          # ConfiguraciÃ³n cluster EMR
â”‚   â””â”€â”€ pipeline_config.yaml     # ParÃ¡metros del pipeline
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 01_procesar_sentinel.py           # Procesar SAFE files
â”‚   â”œâ”€â”€ 02_generar_mascaras.py            # Generar mÃ¡scaras clear sky
â”‚   â”œâ”€â”€ 03_tabular_features.py            # Extraer features por pÃ­xel
â”‚   â”œâ”€â”€ 04_rasterizar_labels.py           # Vectores â†’ raster labels
â”‚   â”œâ”€â”€ 05_unir_features_labels.py        # Join features + labels
â”‚   â”œâ”€â”€ 06_entrenar_modelos_spark.py      # Entrenar RF + GBT (Spark)
â”‚   â”œâ”€â”€ 07_evaluar_modelos.py             # Generar mÃ©tricas
â”‚   â”œâ”€â”€ 08_predecir.py                    # Predicciones nuevas Ã¡reas
â”‚   â”œâ”€â”€ submit_emr_steps.py               # Enviar steps a EMR
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ s3_utils.py                   # Funciones S3
â”‚       â”œâ”€â”€ raster_utils.py               # Funciones rasterio
â”‚       â””â”€â”€ spark_utils.py                # Funciones Spark
â”‚
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf                  # Infraestructura AWS
â”‚   â”œâ”€â”€ emr.tf                   # Cluster EMR
â”‚   â”œâ”€â”€ s3.tf                    # Buckets S3
â”‚   â”œâ”€â”€ iam.tf                   # Roles y policies
â”‚   â””â”€â”€ variables.tf             # Variables Terraform
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yml           # CI/CD con GitHub Actions
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ AWS_SETUP.md             # GuÃ­a configuraciÃ³n AWS
â”‚   â”œâ”€â”€ EMR_GUIDE.md             # GuÃ­a uso EMR
â”‚   â”œâ”€â”€ PIPELINE.md              # DocumentaciÃ³n pipeline
â”‚   â””â”€â”€ TROUBLESHOOTING.md       # ResoluciÃ³n de problemas
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_procesar_sentinel.py
    â”œâ”€â”€ test_tabular_features.py
    â””â”€â”€ test_entrenar_modelos.py
```

---

## ğŸ”„ Pipeline de Datos

### Step 1: Procesar Sentinel-2
```bash
spark-submit \
  --deploy-mode cluster \
  s3://bucket/scripts/01_procesar_sentinel.py \
  --input s3://bucket/raw_sentinel/*.SAFE \
  --output s3://bucket/01_processed/ \
  --bands B01,B02,B03,B04,B05,B06,B07,B08,B8A,B11,B12 \
  --resolution 20
```

### Step 2: Generar MÃ¡scaras
```bash
spark-submit \
  s3://bucket/scripts/02_generar_mascaras.py \
  --input s3://bucket/01_processed/*.tif \
  --output s3://bucket/02_masks/ \
  --clear_classes 4,5,6
```

### Step 3: Tabular Features
```bash
spark-submit \
  --executor-memory 16g \
  s3://bucket/scripts/03_tabular_features.py \
  --rasters s3://bucket/01_processed/*.tif \
  --masks s3://bucket/02_masks/*.tif \
  --output s3://bucket/03_features/composite.parquet \
  --stats median,p10,p90
```

### Step 4-6: Training Pipeline
```bash
# Rasterizar labels
spark-submit s3://bucket/scripts/04_rasterizar_labels.py \
  --bosque_shp s3://bucket/shapes/bosque.shp \
  --output s3://bucket/04_labels/forest_labels.tif

# Unir features + labels
spark-submit s3://bucket/scripts/05_unir_features_labels.py \
  --features s3://bucket/03_features/composite.parquet \
  --labels s3://bucket/04_labels/forest_labels.tif \
  --output s3://bucket/05_training_data/training.parquet

# Entrenar modelos
spark-submit \
  --executor-memory 32g \
  --executor-cores 8 \
  s3://bucket/scripts/06_entrenar_modelos_spark.py \
  --input s3://bucket/05_training_data/training.parquet \
  --out_model s3://bucket/06_models/best_model \
  --out_metrics s3://bucket/07_evaluation/
```

---

## âš™ï¸ ConfiguraciÃ³n AWS

### 1. Requisitos Previos

- AWS CLI configurado
- Terraform instalado
- Cuenta AWS con permisos EMR, S3, IAM

### 2. Desplegar Infraestructura

```bash
cd terraform/
terraform init
terraform plan
terraform apply
```

Esto crea:
- âœ… Bucket S3 (`s3://mineria-data-bucket`)
- âœ… Cluster EMR (Spark 3.5, 1 master + N workers)
- âœ… Roles IAM (EMR_EC2_DefaultRole, EMR_DefaultRole)
- âœ… Security Groups

### 3. Subir Scripts a S3

```bash
aws s3 sync scripts/ s3://mineria-data-bucket/scripts/
aws s3 sync config/ s3://mineria-data-bucket/config/
```

### 4. Subir Datos Raw

```bash
aws s3 sync safe/ s3://mineria-data-bucket/raw_sentinel/
aws s3 sync shapes/ s3://mineria-data-bucket/shapes/
```

---

## ğŸš€ EjecuciÃ³n

### OpciÃ³n 1: EjecuciÃ³n Manual (AWS Console)

1. Ir a **EMR Console**
2. Seleccionar cluster
3. **Add Step** â†’ Custom JAR (spark-submit)
4. Configurar argumentos del script

### OpciÃ³n 2: EjecuciÃ³n ProgramÃ¡tica (Python)

```python
# scripts/submit_emr_steps.py
python scripts/submit_emr_steps.py \
  --cluster-id j-XXXXXXXXXXXXX \
  --step procesar_sentinel \
  --config config/pipeline_config.yaml
```

### OpciÃ³n 3: Pipeline Completo (Airflow/Step Functions)

```bash
# Ejecutar todos los pasos en secuencia
python scripts/submit_emr_steps.py \
  --cluster-id j-XXXXXXXXXXXXX \
  --pipeline full \
  --wait
```

---

## ğŸ“Š Monitoreo

### CloudWatch Logs

```bash
# Ver logs de step
aws emr describe-step \
  --cluster-id j-XXXXXXXXXXXXX \
  --step-id s-XXXXXXXXXXXXX

# Descargar logs
aws s3 sync s3://aws-logs-bucket/emr/j-XXX/steps/ ./logs/
```

### Spark UI

```bash
# TÃºnel SSH
aws emr socks --cluster-id j-XXXXXXXXXXXXX --key-pair-file key.pem

# Acceder: http://master-public-dns:8088
```

### MÃ©tricas S3

```bash
# Ver tamaÃ±o de outputs
aws s3 ls s3://mineria-data-bucket/ --recursive --human-readable --summarize
```

---

## ğŸ’» Desarrollo Local

### Setup Entorno

```bash
# Crear virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Instalar dependencias
pip install -r requirements.txt
```

### Ejecutar Scripts Localmente (Sin Spark)

```bash
# Usar versiÃ³n sklearn en lugar de Spark
python scripts/sklearn_train_bosque_nobosque.py \
  --input data/training_data.parquet \
  --out_model_dir models/ \
  --out_metrics_dir evaluation/
```

### Testing

```bash
pytest tests/
```

---

## ğŸ“ˆ Resultados Esperados

### MÃ©tricas del Modelo

| MÃ©trica | Objetivo | Actual |
|---------|----------|--------|
| Accuracy | > 85% | 90.32% âœ… |
| ROC-AUC | > 90% | 92.41% âœ… |
| F1-Score | > 85% | 89.33% âœ… |

### Costos Estimados AWS

| Recurso | Costo/hora | Costo/dÃ­a (24h) |
|---------|------------|-----------------|
| EMR (m5.xlarge Ã— 3) | $0.30 | $7.20 |
| S3 Storage (100GB) | - | $0.23 |
| Data Transfer | - | ~$0.50 |
| **Total** | - | **~$8/dÃ­a** |

ğŸ’¡ **Tip**: Usar Spot Instances para reducir costos 60-70%

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Optimizar Cluster EMR

```json
// config/emr_config.json
{
  "InstanceGroups": [
    {
      "InstanceRole": "MASTER",
      "InstanceType": "m5.xlarge",
      "InstanceCount": 1
    },
    {
      "InstanceRole": "CORE",
      "InstanceType": "m5.2xlarge",
      "InstanceCount": 5,
      "BidPrice": "0.10"  // Spot instance
    }
  ],
  "Applications": [
    {"Name": "Spark"},
    {"Name": "Hadoop"},
    {"Name": "Hive"}
  ]
}
```

### Particionamiento S3

```
s3://mineria-data-bucket/
â”œâ”€â”€ 03_features/
â”‚   â”œâ”€â”€ year=2019/
â”‚   â”œâ”€â”€ year=2020/
â”‚   â”œâ”€â”€ year=2021/
â”‚   â””â”€â”€ year=2022/
â””â”€â”€ 05_training_data/
    â”œâ”€â”€ finca=finca1/
    â”œâ”€â”€ finca=finca2/
    â””â”€â”€ finca=finca3/
```

---

## ğŸ› Troubleshooting

Ver [docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)

**Problemas comunes:**
- Cluster EMR no inicia â†’ Revisar lÃ­mites de servicio
- Out of Memory â†’ Aumentar `executor-memory`
- S3 access denied â†’ Verificar IAM roles

---

## ğŸ“š Referencias

- [AWS EMR Documentation](https://docs.aws.amazon.com/emr/)
- [Spark MLlib Guide](https://spark.apache.org/docs/latest/ml-guide.html)
- [Rasterio Documentation](https://rasterio.readthedocs.io/)
- [Polars Guide](https://pola-rs.github.io/polars-book/)

---

## ğŸ‘¥ Autores

**Manu** - MinerÃ­a de Datos  
**Ãšltima actualizaciÃ³n**: Noviembre 2025

---

## ğŸ“„ Licencia

MIT License - Ver [LICENSE](LICENSE) para mÃ¡s detalles
