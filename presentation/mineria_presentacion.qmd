---
title: "Clasificación Bosque/No-Bosque"
subtitle: "Proyecto de Minería de Datos con Sentinel-2 y AWS"
author: "Equipo del proyecto"
date: "2025-11-12"
format:
  revealjs:
    theme: [default]
    slide-number: true
    toc: false
    incremental: true
    code-copy: true
    footer: "Proyecto Minería de Datos · AWS EC2/EMR · Sentinel-2"
    embed-resources: true
    smaller: true
    mermaid:
      theme: default
    width: 1600
    height: 900
    maxScale: 2
    minScale: 0.2
    margin: 0.04
execute:
  echo: false
  warning: false
lang: es
---

## Introducción

La deforestación en Colombia responde principalmente a la expansión de la frontera agrícola (tanto por usos legales como ilegales del suelo) y a actividades intensivas de aprovechamiento forestal con fines comerciales y domésticos [1]. Dado el carácter altamente diverso del país, las regiones presentan condiciones biofísicas y dinámicas socioambientales diferenciadas; por ello, el estudio de la deforestación a escala subnacional o subregional es clave para producir diagnósticos más precisos y acciones de manejo focalizadas.

En este contexto, las imágenes satelitales, combinadas con sistemas de información geográfica, se han consolidado como insumos fundamentales para el mapeo y la analítica espacial en ciencia e industria. En ecología forestal, los métodos de aprendizaje de máquina permiten abordar tareas como la identificación de coberturas, la modelación de distribución de especies, la estimación de ciclos de carbono, la gestión del riesgo y el pronóstico. Un insumo crítico para múltiples aplicaciones es la delimitación confiable de áreas forestales en una región dada, información que puede derivarse de sensores como Sentinel‑2 mediante flujos de datos reproducibles y escalables.

---

## Pregunta y Objetivo general

### Pregunta de investigación

¿Qué tan bien puede un modelo de ML basado en variables espectrales de Sentinel-2 diferenciar Bosque de No-Bosque en el área de estudio, bajo un flujo reproducible de datos en AWS?

### Objetivo general

Construir y evaluar un pipeline de punta a punta para clasificar Bosque/No-Bosque usando Sentinel-2, con preprocesamiento robusto, etiquetado confiable, entrenamiento en Spark (EMR) y evaluación con métricas por clase.

---

## Objetivos específicos

- Diseñar el flujo de preprocesamiento y control de calidad (nubes, sombras, nieve).
- Generar etiquetas raster (1=bosque, 0=no-bosque, -1=ignorar) a partir de shapes confiables.
- Tabular features espectrales y temporales y construir el dataset de entrenamiento.
- Entrenar modelos en Spark (Random Forest, GBT) y seleccionar el de mejor desempeño.
- Evaluar con métricas por clase (precisión, recall, F1), matriz de confusión y reporte.
- Orquestar la ejecución en AWS y versionar artefactos en S3 para reproducibilidad.

---

## Datos y características

- Sentinel-2: bandas B01-B12; índices: NDVI, NDWI.
- Reproyección objetivo: EPSG:4326; resolución típica: 20 m.
- Composición temporal (p.ej., median, p10, p90, rango) por banda/índice.

---

## Metodología (visión general)

0) Ingesta de datos (shapes + historial Sentinel-2)  
1) Preprocesamiento imágenes (Sentinel-2)  
2) Máscaras Clear-Sky (nubes, sombras, nieve)  
3) Tabulación de features válidas  
4) Rasterización de etiquetas (bosque/no-bosque)  
5) Unión features + labels (dataset)  
6) Entrenamiento modelos en Spark (EMR)  
7) Evaluación y reporte de métricas

---

## Ingesta de datos 

Dos componentes principales:

1) Subida de shapes a S3  
   - Carga de los shapefiles del área/fin cas objetivo y/o listado de imágenes objetivo.  
   - Organización en el bucket para referencia por los scripts posteriores.  
   - Ejemplo de estructura:  
     - `s3://<bucket>/shapes/`  
     - `s3://<bucket>/lists/imagenes_objetivo.csv`

2) Descarga de datos Sentinel-2  
   - A partir de la definición anterior, búsqueda de las imágenes objetivo y descarga de su histórico.  
   - Se almacenan los productos originales en formato `.SAFE` en S3.  
   - Ruta sugerida: `s3://<bucket>/raw/raw_copernicus/<finca>/.../*.SAFE/`

Notas:
- Esta etapa prepara el “raw zone” del data lake en S3 para el preprocesamiento (01-05).  
- El etiquetado y entrenamiento dependen de que esta ingesta esté completa y consistente.

---

## Preparación de datos (DATA_PREP.md)

- Dataset final consolidado: `s3://mineria-project/data/all/training_data_all_zones.parquet` (8,008 muestras; 15 features).

Paso 1 · Procesar Sentinel-2 (clip)
- Script: `01_procesar_sentinel_clip.py`
- Entrada: `raw/raw_copernicus/ZONA/*.SAFE`, perímetros `raw/shapes/ZONA/Perímetro.shp`
- Salida: `staging/01_rasters_procesados_clipped/ZONA/` (GeoTIFF multibanda, 10 bandas, 10 m, EPSG:4326)

Paso 2 · Tabular features espectrales
- Script: `03_tabular_features.py`
- Extracción pixel a pixel, composición temporal (mediana, p25, p75), `n_obs`
- Salida: `composite_annual.parquet`, `observations_all.parquet` (Polars/Parquet)

Paso 3 · Rasterizar etiquetas (labels)
- Script: `04_rasterizar_labels.py`
- Erosión morfológica de bordes; clases: 1=bosque, 0=no-bosque, -1=ignorar
- Salida: `forest_labels.tif`

Paso 4 · Unir features + labels
- Script: `05_unir_features_labels.py`
- Une medianas/percentiles + label por (x,y); filtra `label=-1`
- Salida: `training_data.parquet` (18 columnas: 15 features + metadata)

Paso 5 · Consolidación multi-zona
- Script: `process_all_zones_pipeline.py`
- Descubre zonas, valida insumos, concatena, añade `zone`, genera reporte
- Salida: `training_data_all_zones.parquet` + `pipeline_report_*.json`

Resumen del dataset (ejemplo reciente)
- Total: 8,008 píxeles; Bosque=22.7%, No-Bosque=77.3% (ratio ≈ 3.4:1)
- Zonas procesadas: 5 de 6; duración total ~65s

---

## Metodología (diagrama de flujo)

<div style="display:flex; align-items:center; justify-content:center; height:80vh; width:100%; margin-top:3vh;">
<div style="display:flex; align-items:center; justify-content:center; gap:28px; flex-wrap:nowrap; width:100%;">
<img src="C:/Users/jmox0/Documents/AWS1.jpg" alt="AWS paso 1" style="max-height:22vh; height:auto; width:auto; object-fit:contain;" />
<span style="font-size:48px; line-height:1;">&rarr;</span>
<img src="C:/Users/jmox0/Documents/AWS2.jpg" alt="AWS paso 2" style="max-height:22vh; height:auto; width:auto; object-fit:contain;" />
<span style="font-size:48px; line-height:1;">&rarr;</span>
<img src="C:/Users/jmox0/Documents/AWS3.jpg" alt="AWS paso 3" style="max-height:22vh; height:auto; width:auto; object-fit:contain;" />
</div>
</div>

---

## Metodología (scripts del repositorio)

- `scripts/01_procesar_sentinel.py`: procesa bandas e índices; reproyección al CRS objetivo.
- `scripts/02_generar_mascaras.py`: máscaras de cielo despejado; heurísticas NDVI/NIR; dilatación.
- `scripts/03_tabular_features.py`: extrae píxeles válidos y compone estadísticas temporales.
- `scripts/04_rasterizar_labels.py`: rasteriza bosque desde shapes; aplica erosión morfológica.
- `scripts/05_unir_features_labels.py`: construye dataset (features + labels, coords x,y).
- `scripts/06_entrenar_modelos_spark.py`: entrena RandomForest/GBT en EMR Spark.
- `scripts/07_evaluar_modelos.py`: calcula y reporta métricas de clasificación.

---

## Infraestructura y orquestación

- EC2 para preprocesamiento (scripts 01–05).  
- EMR para entrenamiento/evaluación (scripts 06–07).  
- S3 para entrada/salida: raw, procesados, features, labels, modelos, resultados.  
- Parámetros en `config/*.yaml` y guías en `EXECUTION_GUIDE.md`.

---

## Ejecución (resumen)

En EC2 (preprocesamiento):

```bash
python scripts/orchestration/run_ec2_pipeline.py --mode sequential
# o bien: --script 01_procesar_sentinel (etc.)
```

En local para lanzar EMR (ML):

```bash
python scripts/orchestration/run_emr_pipeline.py \
  --script 06_entrenar_modelos_spark \
  --create-cluster --auto-terminate
```

---

## Resultados: métricas objetivo

- Exactitud (accuracy) global.  
- Precision y Recall por clase (0=No‑Bosque, 1=Bosque).  
- F1 por clase y macro/micro promedio.  
- Matriz de confusión y reporte interpretativo.

Criterios de éxito sugeridos:

- Recall clase Bosque (1) ≥ 0.85  
- F1 clase Bosque (1) ≥ 0.85  
- Balance razonable precisión/recall (sin sesgo fuerte por clase)

---

## Resultados (interpretación)

- Si el recall de Bosque es bajo → aumentar `class_weight`, ajustar umbral o erosión.  
- Si hay muchos falsos positivos → revisar umbrales y features temporales.  
- Usar el reporte de `scripts/07_evaluar_modelos.py` para recomendaciones.

> Nota: Inserta aquí las métricas reales una vez ejecutado el pipeline y exportado el reporte de evaluación.

---

## Conclusiones

- El pipeline soporta un flujo reproducible y escalable en AWS.  
- La evaluación por clase asegura que el objetivo (bosque/no‑bosque) sea verificable.  
- Próximos pasos: pruebas con datos reales, ajuste fino y validación espacial.

---

## Referencias y guías

- [1] Estudios sobre causas de deforestación en Colombia (síntesis; indicar fuente y año exacto en la versión final).  
- `README.md`, `EXECUTION_GUIDE.md`, `RESUMEN_EJECUTIVO.md`  
- Configuración: `config/*.yaml`  
- Orquestación: `scripts/orchestration/*`
