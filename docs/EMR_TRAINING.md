# Entrenamiento de Modelos en AWS EMR

## üìã Resumen

Este documento describe c√≥mo entrenar y evaluar modelos de Machine Learning usando **AWS EMR (Elastic MapReduce)** con **Apache Spark**. El pipeline est√° optimizado para procesamiento distribuido de datasets grandes.

---

## üèóÔ∏è Arquitectura EMR

### **Componentes del Cluster**

```
EMR Cluster (mineria-ml-cluster)
‚îÇ
‚îú‚îÄ‚îÄ Master Node (m5.xlarge)
‚îÇ   ‚îú‚îÄ‚îÄ YARN ResourceManager
‚îÇ   ‚îú‚îÄ‚îÄ Spark Driver
‚îÇ   ‚îî‚îÄ‚îÄ HDFS NameNode
‚îÇ
‚îî‚îÄ‚îÄ Core Nodes (2x m5.2xlarge)
    ‚îú‚îÄ‚îÄ YARN NodeManager
    ‚îú‚îÄ‚îÄ Spark Executors
    ‚îî‚îÄ‚îÄ HDFS DataNode
```

### **Especificaciones**

| Componente | Tipo | vCPU | RAM | Storage | Funci√≥n |
|------------|------|------|-----|---------|---------|
| **Master** | m5.xlarge | 4 | 16GB | 64GB EBS | Coordinaci√≥n, Spark Driver |
| **Core (x2)** | m5.2xlarge | 8 | 32GB | 2x128GB EBS | Procesamiento, HDFS |
| **Total** | - | 20 | 80GB | 320GB | - |

### **Configuraci√≥n de Spark**

```json
{
  "maximizeResourceAllocation": true,
  "spark.dynamicAllocation.enabled": true,
  "spark.shuffle.service.enabled": true,
  "spark.serializer": "KryoSerializer",
  "spark.sql.adaptive.enabled": true
}
```

---

## üöÄ Deployment del Cluster

### **1. Configurar Variables Terraform**

Editar `infrastructure/terraform.tfvars`:

```hcl
# Configuraci√≥n EMR
emr_master_instance_type  = "m5.xlarge"
emr_core_instance_type    = "m5.2xlarge"
emr_core_instance_count   = 2
emr_key_name              = "your-ssh-key"  # opcional
```

### **2. Crear Cluster EMR**

```bash
cd infrastructure
terraform init
terraform plan
terraform apply
```

**Tiempo de creaci√≥n:** ~10-15 minutos

### **3. Obtener Cluster ID**

```bash
# Desde Terraform output
terraform output emr_cluster_id

# O desde AWS CLI
aws emr list-clusters --active --query 'Clusters[0].Id' --output text
```

---

## üìä Entrenamiento de Modelos

### **Script 06: Entrenamiento**

**Funci√≥n:** Entrena modelos Random Forest y GBT con optimizaci√≥n de hiperpar√°metros.

#### **Pipeline de Entrenamiento**

```
1. Carga de datos desde S3
   ‚Üì
2. Split train/val/test (70/15/15)
   ‚Üì
3. C√°lculo de pesos para balanceo de clases
   ‚Üì
4. Optimizaci√≥n de hiperpar√°metros
   ‚îú‚îÄ‚îÄ Random Forest (Grid Search)
   ‚îî‚îÄ‚îÄ Gradient Boosted Trees (Grid Search)
   ‚Üì
5. Selecci√≥n del mejor modelo (seg√∫n validation)
   ‚Üì
6. Re-entrenamiento con TODO el train set
   ‚Üì
7. Evaluaci√≥n final en test set
   ‚Üì
8. Guardado del modelo en S3
```

#### **Grid de Hiperpar√°metros**

**Random Forest:**
- `numTrees`: [200, 400, 600]
- `maxDepth`: [10, 14, 18]
- `maxBins`: [64, 128]
- `featureSubsetStrategy`: ["sqrt", "log2"]
- **Total combinaciones:** 24

**Gradient Boosted Trees:**
- `maxDepth`: [6, 8, 10]
- `maxBins`: [64, 128]
- `maxIter`: [100, 200]
- `stepSize`: [0.05, 0.1, 0.2]
- **Total combinaciones:** 36

#### **Uso Manual (spark-submit)**

```bash
spark-submit \
  --deploy-mode cluster \
  --master yarn \
  --conf spark.executor.memory=8g \
  --conf spark.executor.cores=4 \
  --conf spark.executor.instances=4 \
  --conf spark.driver.memory=4g \
  s3://mineria-project/source/scripts/06_entrenar_modelos_spark.py \
  --inputs s3://mineria-project/data/all/training_data_all_zones.parquet \
  --out_model_dir s3://mineria-project/models/model_v1/ \
  --label_col label \
  --test_frac 0.15 \
  --seed 42 \
  --metric areaUnderPR
```

#### **Uso con Script Helper**

```bash
# Entrenamiento b√°sico
python scripts/submit_training_emr.py --cluster-id j-XXXXXXXXX

# Entrenar y esperar
python scripts/submit_training_emr.py --cluster-id j-XXXXXXXXX --wait

# Entrenar y evaluar autom√°ticamente
python scripts/submit_training_emr.py \
  --cluster-id j-XXXXXXXXX \
  --evaluate \
  --wait

# Configuraci√≥n custom
python scripts/submit_training_emr.py \
  --cluster-id j-XXXXXXXXX \
  --input-data s3://mineria-project/data/custom/filtered_data.parquet \
  --test-frac 0.2 \
  --metric areaUnderROC \
  --evaluate
```

#### **Outputs del Entrenamiento**

```
s3://mineria-project/models/model_YYYYMMDD_HHMMSS/
‚îú‚îÄ‚îÄ pipeline_best/               # Modelo completo (Pipeline)
‚îÇ   ‚îú‚îÄ‚îÄ metadata/
‚îÇ   ‚îú‚îÄ‚îÄ stages/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 0_VectorAssembler/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 1_RandomForestClassifier/  (o GBTClassifier)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ metrics/
    ‚îú‚îÄ‚îÄ summary.json             # M√©tricas completas
    ‚îî‚îÄ‚îÄ feature_importances.csv  # Importancia de variables
```

**Contenido de `summary.json`:**
```json
{
  "metric_used": "areaUnderPR",
  "train_samples": 5605,
  "val_samples": 1201,
  "test_samples": 1202,
  "n_features": 15,
  "class_weights": {"0.0": 0.65, "1.0": 2.20},
  "models": {
    "RandomForest": {
      "val_metrics": {
        "areaUnderROC": 0.8723,
        "areaUnderPR": 0.7654,
        "accuracy": 0.8234,
        "f1": 0.7890
      },
      "test_metrics": {...},
      "best_params": {
        "numTrees": "400",
        "maxDepth": "14",
        "maxBins": "128"
      }
    },
    "GBT": {...}
  },
  "winner": {
    "name": "RandomForest",
    "val_metrics": {...},
    "test_metrics_retrained": {...}
  },
  "confusion_matrix": {
    "TN": 890,
    "FP": 120,
    "FN": 95,
    "TP": 97
  },
  "feature_importances": [
    {"feature": "B08_med", "importance": 0.1856},
    {"feature": "NDVI_med", "importance": 0.1432},
    ...
  ]
}
```

---

## üìà Evaluaci√≥n de Modelos

### **Script 07: Evaluaci√≥n**

**Funci√≥n:** Eval√∫a modelo guardado y genera reportes detallados.

#### **Uso**

```bash
# Evaluaci√≥n manual
spark-submit \
  --deploy-mode cluster \
  --master yarn \
  s3://mineria-project/source/scripts/07_evaluar_modelos.py \
  --model s3://mineria-project/models/model_20251112_163000/pipeline_best \
  --test_data s3://mineria-project/data/all/training_data_all_zones.parquet \
  --output s3://mineria-project/results/eval_20251112/ \
  --test_fraction 0.15

# O usar el helper con --evaluate
python scripts/submit_training_emr.py --cluster-id j-XXXXXXXXX --evaluate --wait
```

#### **Outputs de Evaluaci√≥n**

```
s3://mineria-project/results/eval_YYYYMMDD_HHMMSS/
‚îú‚îÄ‚îÄ metrics.json                 # M√©tricas JSON
‚îú‚îÄ‚îÄ feature_importance.json      # Importancia detallada
‚îî‚îÄ‚îÄ EVALUATION_REPORT.md         # Reporte legible
```

**M√©tricas Calculadas:**
- AUC-ROC
- AUC-PR
- Accuracy
- F1-Score
- Precision (weighted)
- Recall (weighted)
- Precision por clase (0, 1)
- Recall por clase (0, 1)
- Matriz de confusi√≥n (TN, FP, FN, TP)

---

## üîç Monitoreo y Debugging

### **Verificar Estado del Cluster**

```bash
# Estado general
aws emr describe-cluster --cluster-id j-XXXXXXXXX

# Listar steps
aws emr list-steps --cluster-id j-XXXXXXXXX

# Ver detalles de un step
aws emr describe-step --cluster-id j-XXXXXXXXX --step-id s-XXXXXXXXX
```

### **Acceder a Logs**

```bash
# Logs del cluster
aws s3 ls s3://mineria-project/logs/emr/j-XXXXXXXXX/

# Descargar logs de un step
aws s3 cp s3://mineria-project/logs/emr/j-XXXXXXXXX/steps/s-XXXXXXXXX/ ./logs/ --recursive

# Ver stderr de un step
aws s3 cp s3://mineria-project/logs/emr/j-XXXXXXXXX/steps/s-XXXXXXXXX/stderr.gz - | gunzip
```

### **UIs de Monitoreo**

**Spark History Server:**
```
http://<master-public-dns>:18080
```

**YARN ResourceManager:**
```
http://<master-public-dns>:8088
```

**Para acceder:**
```bash
# 1. Obtener DNS del master
MASTER_DNS=$(aws emr describe-cluster --cluster-id j-XXXXXXXXX \
  --query 'Cluster.MasterPublicDnsName' --output text)

# 2. Crear t√∫nel SSH (si configuraste SSH key)
ssh -i your-key.pem -N -L 8088:localhost:8088 hadoop@$MASTER_DNS

# 3. Abrir en navegador
open http://localhost:8088
```

---

## üí∞ Costos y Optimizaci√≥n

### **Estimaci√≥n de Costos (us-east-1)**

| Componente | Tipo | Precio/hora | Cantidad | Total/hora |
|------------|------|-------------|----------|------------|
| Master | m5.xlarge | $0.192 | 1 | $0.19 |
| Core | m5.2xlarge | $0.384 | 2 | $0.77 |
| EMR Fee | - | 25% | - | $0.24 |
| **Total** | | | | **$1.20/hora** |

**Costos t√≠picos:**
- Entrenamiento completo: **~30 minutos** = **$0.60**
- Evaluaci√≥n: **~10 minutos** = **$0.20**
- **Total por experimento:** **~$0.80**

### **Configuraci√≥n de Auto-terminaci√≥n**

El cluster se termina autom√°ticamente despu√©s de **1 hora de inactividad** para evitar costos innecesarios.

```hcl
# En emr.tf
auto_termination_policy {
  idle_timeout = 3600  # 1 hora
}
```

### **Terminar Cluster Manualmente**

```bash
# Terminar cluster
aws emr terminate-clusters --cluster-ids j-XXXXXXXXX

# O con Terraform
terraform destroy -target=aws_emr_cluster.ml_cluster
```

---

## üõ†Ô∏è Troubleshooting

### **Error: Cluster no disponible**
```
Error: Cluster no est√° disponible (estado: TERMINATED)
```
**Soluci√≥n:** Verificar que el cluster est√© en estado `WAITING` o `RUNNING`:
```bash
aws emr list-clusters --active
```

### **Error: Out of Memory**
```
java.lang.OutOfMemoryError: Java heap space
```
**Soluci√≥n:** Aumentar memoria de executors:
```bash
--conf spark.executor.memory=12g \
--conf spark.driver.memory=6g
```

### **Error: S3 Access Denied**
```
AccessDeniedException: User not authorized
```
**Soluci√≥n:** Verificar IAM roles y pol√≠ticas en `emr.tf` (l√≠nea 74-91).

### **Error: Step Failed**
```
Step failed with error: Command failed with exit code 1
```
**Soluci√≥n:** Revisar logs detallados:
```bash
aws s3 cp s3://mineria-project/logs/emr/j-XXX/steps/s-XXX/stderr.gz - | gunzip | tail -100
```

---

## üìö Referencias

### **Documentaci√≥n AWS**
- [AWS EMR Documentation](https://docs.aws.amazon.com/emr/)
- [Spark on EMR](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark.html)
- [EMR Best Practices](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-instances-guidelines.html)

### **Comandos √ötiles**

```bash
# Listar clusters activos
aws emr list-clusters --active

# Crear cluster desde CLI (alternativa a Terraform)
aws emr create-cluster \
  --name "mineria-ml-cluster" \
  --release-label emr-6.15.0 \
  --applications Name=Spark Name=Hadoop \
  --ec2-attributes KeyName=your-key,InstanceProfile=EMR_EC2_DefaultRole \
  --instance-groups InstanceGroupType=MASTER,InstanceType=m5.xlarge,InstanceCount=1 \
                    InstanceGroupType=CORE,InstanceType=m5.2xlarge,InstanceCount=2 \
  --service-role EMR_DefaultRole \
  --log-uri s3://mineria-project/logs/emr/

# Ver configuraci√≥n de Spark
aws emr describe-cluster --cluster-id j-XXX \
  --query 'Cluster.Configurations' --output json

# Escalar cluster (a√±adir task nodes)
aws emr modify-instance-groups --cluster-id j-XXX \
  --instance-groups InstanceGroupId=ig-XXX,InstanceCount=4
```

---

## ‚úÖ Checklist de Producci√≥n

Antes de ejecutar en producci√≥n:

- [ ] Cluster EMR creado y en estado `WAITING`
- [ ] Scripts 06 y 07 subidos a S3
- [ ] Bootstrap script funcionando correctamente
- [ ] IAM roles configurados con permisos S3
- [ ] Security groups permiten acceso necesario
- [ ] Dataset consolidado disponible en S3
- [ ] Auto-terminaci√≥n configurada (evitar costos)
- [ ] Logs habilitados en S3
- [ ] Budget alerts configuradas en AWS

---

**√öltima actualizaci√≥n:** 2025-11-12  
**Versi√≥n:** 1.0  
**Contacto:** Equipo de MLOps - Proyecto Miner√≠a
